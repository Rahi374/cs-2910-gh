* links:
https://medium.com/@manivannan_data/object-tracking-referenced-with-the-previous-frame-using-euclidean-distance-49118730051a
https://github.com/yehengchen/Object-Detection-and-Tracking
https://github.com/yehengchen/Object-Detection-and-Tracking/tree/master/OneStage/yo
https://github.com/yehengchen/Object-Detection-and-Tracking/tree/master/OneStage/yolo/deep_sort_yolov3

* notes

to compile darknet with cuda and opencv, set GPU and OPENCV in the first few
lines of Makefile to 1

don't forget to ~ln -s /usr/lib/whatever/opencv/opencv.pc /usr/lib/pkgconfig/opencv.pc~

also apply that's guy's update patch:
(honestly, probably need the whole pr at
[https://github.com/pjreddie/darknet/pull/1348/commits]), but at least just
[https://github.com/pjreddie/darknet/pull/1348/commits/24cff08086b573c3341e91d072430c9f624a2208]
is good enough, might need to tweak a bit though

and force opencv4, otherwise it won't find opencv2/opencv.hpp
- my version of the aforementioned commit

and for ric, make sure to set env var:
~PKG_CONFIG_PATH=/usr/local/contrib/lib64/pkgconfig~
for opencv4. tbh the lib (non-64) version should be added as well, but with
what i set up on ric, opencv4 is the only pkgconfig in lib64, and all the
pkgconfigs in lib are for libav stuff.

and make sure to pick up the shared objects:
~LD_LIBRARY_PATH=/usr/local/contrib/lib64:$LD_LIBRARY_PATH~

also point to nvcc, either in the makefile with NVCC, or by adding to path
- ~/usr/local/cuda/bin~
- or ~/opt/cuda-10.1/bin~ on ric

also if you want to use opencv2 with python3 on ric:
~PYTHONPATH=/usr/local/contrib/lib/python3.6/site-packages:$PYTHONPATH~

to use the ffmpeg codecs on gstreamer:
~GST_PLUGIN_PATH=/usr/local/contrib/lib/gstreamer-1.0:$GST_PLUGIN_PATH~

hm, tf2 doesn't workg with the above pythonpath...? but installed --user
works?


when you run yolov3-tf2 make sure to remove the /opt cuda path from
LD_LIBRARY_PATH

and for darknet_video.py make sure to add . to LD_LIBRARY_PATH - oh wait you
only need to do that if you want to run yolo_console_dll (uselib), otherwise
for darknet_video.py you don't need anything special

also if you get that annoying qtwidget thread thing, just try completely
logging out and logging in again (ie. reset the entire ssh connection)

** some measurements (just comparing fps for now)

fps comparison for yolov3 implementations

all these tests were run on MOT17-02-DPM.mp4

- old darknet is with my wrapper
- yolov3-tf: [[https://github.com/zzh8829/yolov3-tf2]]
- tf2-ex: [[https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3]]

|        |new darknet|old darknet|yolov3-tf |tf2-ex|
|        | (fps)     |(fps)      |(fps)     |(fps) |
| min    |      0.00 |       0.39|      0.20|  0.50|
| 1st q  |      6.30 |       3.73|      2.76|  4.89|
| median |     16.90 |       7.04|      4.09|  4.96|
| 3rd q  |     26.70 |      11.93|      8.21|  5.00|
| max    |     46.00 |      13.04|     12.65|  5.25|
| mean   |     17.78 |       7.41|      5.86|  4.85|
| stddev |     12.05 |       3.52|      3.66|  0.48|

histogram of fps of my application (C) using old darknet for yolov3:

[[./img/yolov3-dn-fps.png]]

histogram of fps of python implementation of yolov3 with tf2-ex:

[[./img/yolov3-tf-fps.png]]

histogram of fps of new darknet for detection:

[[./img/darknet-new-fps-detect.png]]

histogram of fps of yolov3-tf:

[[./img/yolov3-tf2-fps-detect.png]]

* baseline

** First try

base darknet run
~./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg~

live detector
~./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights videofile~

on neptunite:
data/dog.jpg: Predicted in 12.952805 seconds.
dog: 100%
truck: 92%
bicycle: 99%

on peridot:
data/dog.jpg: Predicted in 79.676022 seconds.
dog: 100%
truck: 92%
bicycle: 99%

of course cpu takes longer on peridot :)


hm, regular run with real-time webcam crashes
137 = sigkill, probably oom?
let's try the tiny weights

it runs on tiny? but freezes? maybe network bw issue? let's try on hdmi
hm yeah looks like it crashed

hm looks like not enough power coz it sometimes crashes with just qv4l2 or
just regular image detection (with tiny weights)
imma get the 5V/4A power adapter
i only have 5V/2A right now :/

power adapter arrived! yolo tiny runs! but it can only recognize people...
and misclassified my watch as a cellphone once lol
i wonder if it can work with the regular yolo... nope, it still dies at step
17, probably oom
yeah it got killed by the oom killer - ah, we only have 4GB of ram
- swap? looks like it comes with 2GB of swap

great, undocumented parameters to detector demo
-w for width, -h for height, -fps for fps
and i think these extra params go after the cfgs and the weights and stuff
coz those use positional args
also after weights you can specify input file name

i got 10 fps with 480p! and 240p. and 160p.
8 fps with 720p
5 fps with 1080p

hm, 9 fps with motchallenge 17 @360p

** Getting the video codecs, on ric

hm darknet with an input video doesn't work for some reason :/
on ric at least; it works on neptunite

#+BEGIN_SRC log
./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights ../../one_evening_in_campo_santa_maria_nova_venice_1080p.mp4
...
video file: ../../one_evening_in_campo_santa_maria_nova_venice_1080p.mp4
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (1743) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (1743) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (1759) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module uridecodebin0 reported: Your GStreamer installation is missing a plug-in.
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (888) open OpenCV | GStreamer warning: unable to start pipeline
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (480) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created
Couldn't connect to webcam.
: Success
darknet: ./src/utils.c:256: error: Assertion `0' failed.
zsh: abort (core dumped)  ./darknet detector demo cfg/coco.data
cfg/yolov3.cfg yolov3.weights 
#+END_SRC

hm list gstreamer plugins...
ah, ric is missing h264 decoder lol. and a bunch of other codecs actually
alright, i'll convert the video to... wait ffmpeg comes with libavcodec... is
that sufficient?

okay yeah i had to install ffmpeg (4.2.2) and then gst-libav (1.10.4, to
match the gstreamer version on ric). oh also needed meson to build gst-libav.
also set the environment variable: see above

okay so now the darknet demo detector works! on the "one evening in campo sant
maria nova venice" 1080p. i get 12~17 fps, and it segfaults :)

oops i guess i was running the wrong version of the video. this time i tried
MOT17-02-DPM. got 3~18 fps, and it still segfaults. it does get through most
(or all) of the video, though (but also it's only 40 seconds, and the last
one was a lot more).

** Fixing the segfault

okay here's the segfault:
#+BEGIN_SRC log
==51380== Process terminating with default action of signal 11 (SIGSEGV)
==51380==  Access not within mapped region at address 0x51F02D770
==51380==    at 0x9B30960: icv_l9_owniSwapChannels_8u_C3R (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_imgproc.so.4.2.0)
==51380==    by 0x9B2FDE6: icv_l9_ippiSwapChannels_8u_C3R (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_imgproc.so.4.2.0)
==51380==    by 0x96AF774: cv::CvtColorIPPLoop_Invoker<cv::IPPReorderFunctor>::operator()(cv::Range const&) const (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_imgproc.so.4.2.0)
==51380==    by 0xB0B963D: (anonymous namespace)::ParallelLoopBodyWrapper::operator()(cv::Range const&) const (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0xB0B9FDA: cv::ParallelJob::execute(bool) [clone .constprop.44] (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0xB0BAC9C: cv::WorkerThread::thread_body() (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0xB0BAE52: cv::WorkerThread::thread_loop_wrapper(void*) (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0x166B6DD4: start_thread (in /usr/lib64/libpthread-2.17.so)
==51380==    by 0x169C8EAC: clone (in /usr/lib64/libc-2.17.so)
==51380==  If you believe this happened as a result of a stack
==51380==  overflow in your program's main thread (unlikely but
==51380==  possible), you can try to increase the size of the
==51380==  main thread stack using the --main-stacksize= flag.
==51380==  The main thread stack size used in this run was 8388608.
==51380== 
==51380== HEAP SUMMARY:
==51380==     in use at exit: 7,464,752,931 bytes in 220,573 blocks
==51380==   total heap usage: 513,540 allocs, 292,967 frees, 8,719,829,795 bytes allocated
==51380== 
==51380== LEAK SUMMARY:
==51380==    definitely lost: 16,549 bytes in 2 blocks
==51380==    indirectly lost: 0 bytes in 0 blocks
==51380==      possibly lost: 4,179,136 bytes in 8,483 blocks
==51380==    still reachable: 7,460,360,630 bytes in 211,014 blocks
==51380==                       of which reachable via heuristic:
==51380==                         stdstring          : 11,695 bytes in 213 blocks
==51380==                         length64           : 11,680 bytes in 253 blocks
==51380==                         newarray           : 2,112 bytes in 52 blocks
==51380==         suppressed: 0 bytes in 0 blocks
==51380== Rerun with --leak-check=full to see details of leaked memory
==51380== 
==51380== For counts of detected and suppressed errors, rerun with: -v
==51380== Use --track-origins=yes to see where uninitialised values come from
==51380== ERROR SUMMARY: 10000000 errors from 5 contexts (suppressed: 0 from 0)
zsh: segmentation fault (core dumped)  valgrind ./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights 
#+END_SRC

ah, this is the right segfault (i think):

#+BEGIN_SRC log
==61104== 
==61104== Process terminating with default action of signal 8 (SIGFPE)
==61104==  Integer divide by zero at address 0x1012255804
==61104==    at 0x490B78: correct_yolo_boxes (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x491263: get_yolo_detections (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x4627C7: fill_network_boxes (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x46297E: get_network_boxes (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x480477: detect_in_thread (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x166B6DD4: start_thread (in /usr/lib64/libpthread-2.17.so)
==61104==    by 0x169C8EAC: clone (in /usr/lib64/libc-2.17.so)
==61104== 
==61104== HEAP SUMMARY:
==61104==     in use at exit: 7,378,105,383 bytes in 217,404 blocks
==61104==   total heap usage: 717,776 allocs, 500,372 frees, 22,314,494,019 bytes allocated
==61104== 
==61104== LEAK SUMMARY:
==61104==    definitely lost: 16,549 bytes in 2 blocks
==61104==    indirectly lost: 0 bytes in 0 blocks
==61104==      possibly lost: 3,315,272 bytes in 8,484 blocks
==61104==    still reachable: 7,374,577,706 bytes in 207,847 blocks
==61104==                       of which reachable via heuristic:
==61104==                         stdstring          : 11,695 bytes in 213 blocks
==61104==                         length64           : 11,680 bytes in 253 blocks
==61104==                         newarray           : 2,112 bytes in 52 blocks
==61104==         suppressed: 0 bytes in 0 blocks
==61104== Rerun with --leak-check=full to see details of leaked memory
==61104== 
==61104== For counts of detected and suppressed errors, rerun with: -v
==61104== Use --track-origins=yes to see where uninitialised values come from
==61104== ERROR SUMMARY: 10000000 errors from 5 contexts (suppressed: 0 from 0)
zsh: floating point exception (core dumped)  valgrind ./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights 
#+END_SRC

okay let's start the debugging
- oh wait valgrind already gave us the callstack lol

#+BEGIN_SRC call stack
start_thread
> detect_in_thread
  > get_network_boxes
    > fill_network_boxes
      > get_yolo_detection
        > correct_yolo_boxes
#+END_SRC

hm okay so i actually checked all my debug prints, and they all have 960x540,
which is the resolution of the video. when the program crashes with the
divide-by-zero, those are zero
- soooo maybe it's the last frame that's killing it?

i think it's not stopping at all actually

so ~get_network_boxes~ (from ~avg_preditions~ in ~detect_in_thread~) gets the
buffer height and width from the global video buffer ring buffer, which has
zeroes, and causes ~correct_yolo_boxes~ down the call stack to divide-by-zero

- ~get_image_from_stream()~ returns an empty 0x0 frame when no frame is
  available
- global video buffer rig buffer ~buff~
- set ~demo_done~ to true when done

ah, okay ~fetch_in_thread()~ does actually set ~demo_done~ to true when
~get_image_from_stream()~ returns an empty frame
- the problem is that ~fetch_in_thread()~ and ~detect_in_thread()~ are both
  in separate threads, racing :)
  - i think the solution is to just put an extra layer of protection in
    ~detect_in_thread()~, such that if the height and width are zero, then
    don't do anything (coz ~fetch_in_thread()~ is alraedy going to end the
    demo loop, so we just have to avoid the crash)

oh also it looks like ~avg_predictions~ was using buff index 0 all the time
so i fixed that to buff_index (log2)

and yeah i added extra protection in ~detect_in_thread()~ to exit if the
frame size is zero. it worked! (log3)

so now time to actually put stuff together

** Putting stuff together

idk if this helps? anyway saving the link just in case
[[https://github.com/entrehuihui/darknet-golang/]]

~parse_network_cfg~

oh yeah forgot to note down that the entry point is in ~examples/darknet~

there's ~run_detector()~ and ~test_detector()~... i wonder how different they
are
- this might be the key to making a simple enough pipeline :)
- then just need to hook it up with the C++ deep sort implementation...

okay so im comparing from ~test_detector()~ to ~run_detector()~:

#+BEGIN_SRC C
read_data_cfg()
option_find_str(..., "data/names.list")
get_labels()
// then ~run_detector()~ calls ~demo()~
load_alphabet()
load_network()
set_batch_network()
#+END_SRC

okay im pretty sure that's the initialization... let's go ahead and burn that
to a file

function prototype for our ~test_detector()~, with default values:
#+BEGIN_SRC C
void test_detector(char *datacfg : "cfg/coco.data",
                   char *cfgfile : "cfg/yolov3.cfg",
                   char *weightfile : "yolov3.weights",
                   char *filename : data/dog.jpg,
                   float thresh : 0.5,
                   float hier_thresh : 0.5,
                   char *outfile : outfile,
                   int fullscreen : fullscreen);
#+END_SRC

after that... (for single image)
#+BEGIN_SRC C
float *X = sized.data;
time = what_time_is_it_now();
network_predict(net, X);
printf("%s: Predicted in %f seconds.\n", input, what_time_is_it_now()-time);

int nboxes = 0;
detection *dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, 0, 1, &nboxes);
if (nms)
      do_nms_sort(dets, nboxes, l.classes, nms);

draw_detections(im, dets, nboxes, thresh, names, alphabet, l.classes);
free_detections(dets, nboxes);
#+END_SRC

okay i think i got a minimal darknet application

** Misc stuff from putting stuff together

after ~network_predict(net, X);~:
#+BEGIN_SRC C
// not sure what this does; anyway it comes from demo
// copy if you need it, but let's try without for now
// remember_network(net);
#+END_SRC

pretty sure we can ignore the ret val of this, coz i think it's just a keycode?

Not necessary to make a window, coz we'll draw the frames later

Not sure what ~set_batch_network()~ does

** Connecting the detector

hm so the original implementation is in python:
[[https://github.com/nwojke/deep_sort]]

and there are some c++ implementations...
- [[https://github.com/oylz/DS]] - old, can't get it to compile
- [[https://github.com/apennisi/deep_sort]] - looks promising
- [[https://github.com/shaoshengsong/DeepSORT]] - not sure, but another one
  in case the previous one fails

in the worst case maybe i'll call into python or something... or implement my
own :/

** Converting to tensorflor

Mosse and Ridrigo recommend that i switch to tf... that might be better
actually :/

DS doesn't want to play nice with boost...

tf is having a hard time compiling... i hope it works

pip worked for some reason

also deep_sort (C++) didn't work coz boost version mismatch? missing header

and DeepSort (also C++) has no build so um yeah :/

we're going to have to go with the tf implementations...

hm... i have a guess deep_sort from deep_sort_yolov3 doesn't depend on tf at
all (the yolov3 portion depends on tf1), so we might actually be able to use
that in python darknet... let's see :)
- from here [[https://github.com/Qidian213/deep_sort_yolov3/]]

*** new darknet python detections format

[bytestring of label, confidence, bounding box]

[(b'person', 0.9992530941963196, (308.0138244628906, 232.64064025878906,
38.53749084472656, 138.75567626953125)), (b'person', 0.9866634607315063,
(137.091064453125, 220.35328674316406, 25.921817779541016, 97.487060546875)),
(b'person', 0.9322742819786072, (162.37936401367188, 198.82156372070312,
9.020377159118652, 42.37779235839844)), (b'person', 0.837138831615448,
(375.0699462890625, 200.4085235595703, 22.553640365600586,
59.19319534301758)), (b'person', 0.8317587971687317, (330.0757751464844,
229.74639892578125, 26.68379020690918, 108.94158935546875)), (b'person',
0.7632826566696167, (106.59329223632812, 226.11199951171875,
26.079158782958984, 100.47222137451172)), (b'person', 0.7058770060539246,
(276.49200439453125, 189.14573669433594, 8.444928169250488,
41.20795440673828)), (b'handbag', 0.5843681693077087, (97.74515533447266,
226.93496704101562, 18.03496551513672, 24.689504623413086)), (b'umbrella',
0.5733580589294434, (374.95709228515625, 163.89324951171875,
25.796112060546875, 9.90929126739502)), (b'person', 0.5225788354873657,
(153.6721954345703, 204.23947143554688, 8.81717300415039,
52.854156494140625)), (b'person', 0.43799227476119995, (406.5743713378906,
215.89390563964844, 15.703649520874023, 74.89576721191406)), (b'person',
0.41168326139450073, (241.92977905273438, 194.4013671875, 10.230013847351074,
47.96332550048828)), (b'person', 0.3753121793270111, (206.500732421875,
182.40682983398438, 7.391855716705322, 32.68758010864258)), (b'person',
0.32717615365982056, (122.51595306396484, 195.37823486328125,
9.457942008972168, 36.52040481567383)), (b'person', 0.27769872546195984,
(226.16036987304688, 187.29954528808594, 8.413454055786133,
36.14714431762695)), (b'person', 0.27708911895751953, (286.1336669921875,
187.1359100341797, 9.223457336425781, 45.986568450927734))]

yep, here's the code:

~res.append((nameTag, dets[j].prob[i], (b.x, b.y, b.w, b.h)))~

and deep sort expects detections like:

~def __init__(self, tlwh, confidence, feature):~

where tlwh is bbox (x, y, w, h), confidence is confidence, and feature is
array_like: "a feature vector that describes the object contained in this
image"
- darn how can i get that from darknet...

** back to new darknet

okay looks like we only have opencv; no zed and stuff

okay so the original yolo_console_dll had a single buffer between the stages
- i chagned the queue and now we're monitoring it every 10ms, but only one
  buffer is being used...
- except for when we turn on image display, then that buffer is the bottlneck
- when we turn off display we have a flat 15 fps
  - the original video is 25 fps

** Documentation for our version

gpu is required

optional ~-i N~ - N to set the gpu index (default 0)

* code stuff

okay while waiting for the adapter, let's check the code
entry point is ~examples/detector.c:run_detector()~
that calls into ~src/demo.c:demo()~, which is the main run loop for the thing
and then ~fetch_in_thread()~ and ~detect_in_thread()~ is the main contents of the
loop
looks like all symbols are exported by libdarknet so it shouldn't be that
hard to stitch together? anyway im not done reading fetch and detect yet

~fetch_in_thread()~:
- free buffer
- get buffer from stream: ~src/image_opencv.cpp:get_image_from_stream()~
- put the boxed image into the main image buffer: ~src/image.c:letterbox_image_into()~

where does buff_letter come from? it is predicted from the last frame in
~detect_in_thread()~?

~letterbox_image_into()~:
- ~resize_image()~ (i think it's resizing to the size of the bounding box?)
- ~embed_image()~ - puts an image into an image... here it's putting the boxed
  image into the main image it looks like
- ~free_image()~ - free the temporarily allocated ~image from resize_image()~

~detect_in_thread()~:
- i think applying the network: ~src/network.c:network_predict()~
- im guessing caching the network/application: ~src/demo.c:remember_network()~
- not sure: ~src/demo.c:avg_predictions()~
  - goes into ~src/box.c:do_nms_obj()~
    - i have no idea what this does - thanks for the commit message: "MERRY
      CHRISTMAS I BROKE ALL YOUR DETECTION THINGS"
- ~draw_detections()~
- ~free_detections()~, and update the (global) buffer index

~src/network.c:network_predict()~:
- ~forward_network()~ -> ~forward_network_gpu()~
  - cuda stuff

* new stuff

nvprof result (baseline)
#+BEGIN_SRC nvprof
==187085== Profiling application: ./uselib -o ../../download/MOT20-01.mp4
==187085== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   35.20%  2.55320s     13696  186.42us  140.16us  270.56us  maxwell_scudnn_winograd_128x128_ldg1_ldg4_tile148n_nt
                   13. 91%  1.00909s     10272  98.236us  63.359us  138.37us  maxwell_scudnn_128x128_relu_interior_nn
                    8.33%  604.23ms      2996  201.68us  198.97us  230.24us  void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)
                    7.77%  563.33ms     13696  41.131us  3.5840us  136.99us  void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)
                    6.23%  451.78ms     32100  14.074us  2.5280us  142.49us  add_bias_kernel(float*, float*, int, int, int, int)
                    4.20%  304.53ms      1284  237.17us  113.47us  335.45us  void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)
                    3.30%  239.37ms       428  559.29us  557.37us  573.56us  void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)
                    3.15%  228.72ms     30816  7.4220us  1.4710us  87.232us  activate_array_leaky_kernel(float*, int)
                    3.00%  217.84ms      1346  161.84us     960ns  8.9544ms  [CUDA memcpy HtoD]
                    2.90%  210.37ms      1713  122.81us  14.016us  225.28us  [CUDA memcpy DtoH]
                    2.51%  182.38ms      9844  18.526us  5.5040us  80.032us  shortcut_singlelayer_simple_kernel(int, int, int, int, int*, float**, float*, float*, float*, int, WEIGHTS_NORMALIZATION_T)
                    2.06%  149.40ms      1712  87.264us  70.976us  110.66us  void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)
                    1.88%  136.07ms       856  158.96us  125.15us  193.92us  void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)
                    1.55%  112.78ms       428  263.49us  252.86us  293.02us  maxwell_scudnn_128x64_relu_small_nn
                    1.53%  110.68ms       428  258.59us  257.12us  291.97us  maxwell_scudnn_128x128_relu_small_nn
                    0.56%  40.970ms       856  47.861us  44.031us  55.839us  maxwell_scudnn_128x64_relu_interior_nn
                    0.55%  39.704ms       428  92.766us  91.103us  101.47us  maxwell_scudnn_128x32_relu_small_nn
                    0.32%  23.537ms     12840  1.8330us  1.3760us  7.3920us  cudnn::maxwell::gemm::computeOffsetsKernel(cudnn::maxwell::gemm::ComputeOffsetsParams)
                    0.30%  21.840ms       428  51.028us  49.311us  54.559us  maxwell_scudnn_128x32_relu_interior_nn
                    0.27%  19.316ms      3852  5.0140us  1.6960us  12.352us  simple_copy_kernel(int, float*, float*)
                    0.24%  17.277ms      7704  2.2420us  1.4400us  6.0480us  activate_array_logistic_kernel(float*, int)
                    0.21%  14.946ms       856  17.459us  12.384us  24.767us  upsample_kernel(unsigned long, float*, int, int, int, int, int, int, float, float*)
                    0.04%  2.8648ms       856  3.3460us  2.4000us  4.4800us  fill_kernel(int, float, float*, int)
                    0.00%  6.2400us         4  1.5600us  1.3440us  2.1760us  [CUDA memset]
      API calls:   58.33%  5.37562s       429  12.531ms  215.07us  13.415ms  cudaStreamSynchronize
                   20.72%  1.90914s         8  238.64ms  2.1460us  1.90881s  cudaStreamCreateWithFlags
                   12. 48%  1.15036s    146376  7.8580us  6.2530us  725.65us  cudaLaunchKernel
                    3.99%  367.77ms       561  655.55us  2.7940us  340.63ms  cudaMalloc
                    2.42%  223.16ms      3058  72.976us  4.3870us  9.3669ms  cudaMemcpyAsync
                    0.59%  54.379ms    123378     440ns     273ns  652.03us  cudaGetDevice
                    0.57%  52.427ms    315148     166ns     104ns  714.73us  cudaGetLastError
                    0.36%  33.271ms       552  60.274us     747ns  1.9029ms  cudaFree
                    0.20%  18.802ms      7276  2.5840us  1.3250us  27.589us  cudaBindTexture
                    0.17%  15.695ms     87459     179ns     107ns  638.04us  cudaPeekAtLastError
                    0.06%  5.5829ms         8  697.87us  24.149us  1.6312ms  cudaHostAlloc
                    0.05%  5.0491ms      7276     693ns     429ns  9.2750us  cudaUnbindTexture
                    0.02%  2.0369ms         7  290.99us  10.961us  763.91us  cudaFreeHost
                    0.01%  891.00us         2  445.50us  431.86us  459.14us  cuDeviceTotalMem
                    0.01%  871.39us       190  4.5860us     129ns  187.48us  cuDeviceGetAttribute
                    0.01%  473.02us         1  473.02us  473.02us  473.02us  cudaGetDeviceProperties
                    0.00%  83.855us         2  41.927us  35.906us  47.949us  cuDeviceGetName
                    0.00%  61.639us         4  15.409us  10.258us  27.706us  cudaMemsetAsync
                    0.00%  33.742us         2  16.871us  16.068us  17.674us  cudaStreamCreate
                    0.00%  31.059us         1  31.059us  31.059us  31.059us  cudaMemcpy
                    0.00%  26.148us        28     933ns     441ns  9.9830us  cudaEventCreateWithFlags
                    0.00%  16.408us         6  2.7340us  1.6040us  6.2550us  cudaSetDevice
                    0.00%  14.876us         4  3.7190us  2.0160us  6.5090us  cudaStreamCreateWithPriority
                    0.00%  12.828us        29     442ns     283ns  2.7970us  cudaDeviceGetAttribute
                    0.00%  10.314us         1  10.314us  10.314us  10.314us  cudaDeviceGetStreamPriorityRange
                    0.00%  10.014us         1  10.014us  10.014us  10.014us  cudaEventRecord
                    0.00%  5.8650us         1  5.8650us  5.8650us  5.8650us  cuDeviceGetPCIBusId
                    0.00%  4.2490us         1  4.2490us  4.2490us  4.2490us  cudaHostGetDevicePointer
                    0.00%  3.0750us         3  1.0250us     190ns  2.4340us  cuDeviceGet
                    0.00%  2.5630us         1  2.5630us  2.5630us  2.5630us  cudaGetDeviceCount
                    0.00%  1.6620us         4     415ns     155ns  1.0250us  cuDeviceGetCount
                    0.00%     782ns         1     782ns     782ns     782ns  cuInit
                    0.00%     497ns         2     248ns     239ns     258ns  cuDeviceGetUuid
                    0.00%     394ns         1     394ns     394ns     394ns  cuDriverGetVersion
#+END_SRC


use the "custom tracking function" coz it's simpler

okay here's what we'll do
1 - split draw and track into separate threads - done
2a - make a type of queue that does cudaMalloc and stuff
2b - convert the following CORE functions to cuda
     - draw_boxes is lowest priority (because of the heavy calling into opencv2)

so preproc has 3 steps, input is cv mat, output is image_t
- resize - mat_to_image_resize()
  - cv::resize (cv::cuda::resize ?)
- DONE convert colorspace - mat_to_image()
  - cv::cvtColor (cv::cuda::cvtColor ?)
- DONE convert from cv mat to image_t - mat_to_image_custom()

for detect... it's a deep call stack, and it calls into the gpu a few times
- entry point is detect_resized; follow that

for tracking... looks like it's all on cpu
- entry point is tracking_id; then it's a big loop (embarrasingly
  parallelizable?)


#+BEGIN_SRC C
det_image = detector.mat_to_image_resize(detection_data.cap_frame);
> in yolo_v2_class.hpp, std::shared_ptr<image_t> mat_to_image_resize(cv::Mat mat) const

result_vec = detector.detect_resized(*det_image, frame_size.width, frame_size.height, thresh, true);
> in yolo_v2_class.hpp, std::vector<bbox_t> detect_resized(image_t img, int init_w, int init_h, float
thresh = 0.2, bool use_mean = false)
  - calls into detect, somewhere

result_vec = detector.tracking_id(result_vec, true, frame_story, 40);
> LIB_API std::vector<bbox_t> Detector::tracking_id(std::vector<bbox_t>
cur_bbox_vec, bool const change_history, int const
frames_story, int const max_dist)

draw_boxes(draw_frame, result_vec, obj_names, current_fps_det, current_fps_cap, detection_data.frame_id);
#+END_SRC

- technically we need a better way to display images (proper threading, via
  Qt or something), but out of scope for this project
- looks like write to video doesn't work... lower priority
- draw_boxes should also be parallelized, tbh, but it calls into so many
  opencv routines for drawing, which is better replaced by some other display
  system anyway


2020/04/22 plan

here's what we're going to do for resize, based on opencv's opencl's resize
sampler. it's not 100% the same result as opencv's results, but it's close
enough, i think.

#+BEGIN_SRC python
for r in range(0, 224):
    for c in range(0, 224):
        sx = (c+0.5) * ifx
        sy = (r+0.5) * ify
        dst[r][c][0] = img[round(sy)][round(sx)][0]
        dst[r][c][1] = img[round(sy)][round(sx)][1]
        dst[r][c][2] = img[round(sy)][round(sx)][2]
#+END_SRC

- okay, the matrix resize worked really well

after that port the tracker, then get see if you can move the detector more
into the gpu

- the detector i don't think can be moved. too complex. there's a layer (C)
  class, and layers inherit from it, and implement the forward_layer_gpu
  function (among other gpu functions)

also think about drawing bounding boxes on gpu (how to draw multiple strings
in parallel onto one image? ask mosse if you need to)

then do the gpu buffers

2020/04/23 plan

oops i forgot to ask about the drawing in the meeting

anyway here are the goals for today:
- move tracking to gpu (just copy the queue into vector for now, it's
  "constant" time anyway)
- add accuracy metric (just do a script to read the console output)
- fix video output
- nvvp to check when and where and if there is memcpying between cpu and gpu
  in the detect stage

2020/04/24 plan

- video output is getting messed up somewhere. display looks weird, and can't
  write to file
  - when i converted to 1080p there was no problem... 1173x880 and 1174x880
    both had problems... (video is warped *right* after capture)
  - and 1920x880 had no problem... looks like it's the width that's affecting
    something?
    - 1280x880 has no problem too
    - according to that guy below, 960 should work fine but 900 will die...
      - well they both work so idk
  - somebody else had the same problem lol but no solution:
    - [[https://github.com/opencv/opencv/issues/12466]]
  - and so yeah, accuracy for 03_1080p is 0.0741771014799339, and for
    05_1080p is 0.06823262068892068 (both without kalman)

- move tracking to gpu

- nvvp to check when and where memcpying happening for detection

- nvvp dlib to see if it does gpu calls
  - nope

- baseline isn't outputting anything

- change memcpy into preproc to async
  - host-to-device memcpy: 1.23ms
  - preprocessing on GPU:  15us
  - device-to-host memcpy: 160us
- sync memcpy
  - host-to-device memcpy:  1.28ms
  - preprocessing (on GPU): 14us
  - device-to-host memcpy:  160us

2020/04/26

after tracking gpu, prev_bbox_vec is messed up

but cur_bbox_vec seems to be fine? it has 1232 elements after the first (non
initial) frame... wait no a bunch of it is garbage...
so maybe an issue with the lenth/bounds checker?

2020/04/27

okay fixed that issue yesterday - i was regenerating the bbox vector with
size * sizeof(bbox_t); you don't need the sizeof

now we have a problem where there are only 3 frames with detections, first
and third have matching tracking ids, but frame 2 has a new set of tracking
ids. need to investigate.

#+BEGIN_SRC log
warning: Cuda API error detected: cudaGetLastError returned (0x2bd)

CUDA status Error: file: ./src/yolo_v2_kernels.cu : () : line: 172 : build
time: Apr 27 2020 - 19:16:09 

 CUDA Error: too many resources requested for launch
 CUDA Error: too many resources requested for launch: Success
 uselib: ./src/utils.c:325: error: Assertion `0' failed.
 `
#+END_SRC

there's a piece of garbage entering the first element of every row in the
(post-sorted) dist_index_pairs
- fixed

#+BEGIN_SRC log
Thread 12 "uselib" received signal CUDA_EXCEPTION_5, Warp Out-of-range
Address.
[Switching focus to CUDA kernel 3, grid 36127, block (0,1,0), thread
(0,15,0), device 0, sm 4, warp 6, lane 16]
0x00007fff788386c8 in __uAtomicCAS ()
#+END_SRC


2020/04/29

okay here's how to validate that all trackings are unique:

~for frame in $(seq 0 427); do grep "Entry f $frame " log | grep person | awk '{ print $11 }' | ruby -e "a = STDIN.map{|s| s.to_i}; puts a.length == a.uniq.length"; done~

2020/04/30

the cuda-queue between preproc and detection worked, but the detection stage
has some simple post-processing on cpu that would be difficult to port to
gpu...

in ~Detector::detect(detection_data_t &, float)~ (src/yolo_v2_class.cpp), the
main two functionality calls are ~network_predict_prealloc~ and ~get_network_boxes~.
~network_predict_prealloc~ is the call that has been ported to cuda-queue.
The latter has not.

The call stack for ~get_network_boxes~ is as follows:
#+BEGIN_SRC C
detection *get_network_boxes(...) (src/network.c)
> void fill_network_boxes(net, ... output_param) (src/network.c)
#+END_SRC

~fill_network_boxes~ loops through all layers in the network, and for all
YOLO layers (there is one output YOLO layer and 2 non-output YOLO layers), it
calls ~size_t get_yolo_detections(layer, ... output_param)~ (src/yolo_layer.c).

~get_yolo_detections~ loops through the output of the yolo layer, and wraps
them in detection objects to output (as a list of detection objects). The
output of the layer is actually cuda memcpied over in yolo layer's
implementation of ~forward_gpu~, which is ~forward_yolo_layer_gpu~ in
src/yolo_layer.c. It hits the ~if(!state.train || l.onlyforward)~ condition
and does ~cuda_pull_array_async~ to pull the output of the layer from the gpu
into the cpu. This last point doesn't seem to cause so much memcpying
overhead for the internal layers though, so idk how that's working.

Anyway, if it was just that last part that's the case (memcpy from device to
host at the end of the yolo layer), I could move that to stay in the gpu
pretty easily. The problem is that the output is aggregated from multiple
layers, plus there's extra data transformation on top of that. There's also a
small resize loop in ~Detector::detect_resized()~ after we finish the deep
gpu and neural network call stack (include/yolo_v2_class.hpp).

* misc

i worked so hard and wrote this prefix sum and gather cuda code (untested),
so just saving it here

#+BEGIN_SRC 
__device__ void bbox_prefix_sum(int *prefix_sum_out, bbox_t *bbox_vec_in, int bbox_len)
{
	int idy = blockDim.y * blockIdx.y + threadIdx.y;
	int pout = 0, pin = 1;

	if (idy < bbox_len) {
		prefix_sum_out[pout*bbox_len + idy] = (idy > 0) ? (bbox_vec_in[idy-1] == 0) : 0;
		__syncthreads();

		for (int offset = 1; offset < bbox_len; offset *= 2)   {
			pout = 1 - pout;
			pin = 1 - pout;
			if (idy >= offset)
				prefix_sum_out[pout*bbox_len + idy] += prefix_sum_out[pin*bbox_len + idy - offset];
			else
				prefix_sum_out[pout*bbox_len + idy] = prefix_sum_out[pin*bbox_len + idy];
			__syncthreads();
		}
	}
}

__device__ void bbox_gather(bbox_t *bbox_vec_out, int *scan_vec, bbox_t *bbox_vec_in, int bbox_len)
{
	int idy = blockDim.y * blockIdx.y + threadIdx.y;

	if (idy < bbox_len) {
		if (idy + 1 == bbox_len) {
			if (bbox_vec_in[idy].track_id == 0)
				bbox_vec_out[idy] = bbox_vec_in[idy];
		} else if (scan_vec[idy] != scan_vec[idy + 1]) {
			bbox_vec_out[scan_vec[idy]] = bbox_vec_in[idy];
		}
	}
}
#+END_SRC
