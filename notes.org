* links:
https://medium.com/@manivannan_data/object-tracking-referenced-with-the-previous-frame-using-euclidean-distance-49118730051a
https://github.com/yehengchen/Object-Detection-and-Tracking
https://github.com/yehengchen/Object-Detection-and-Tracking/tree/master/OneStage/yo
https://github.com/yehengchen/Object-Detection-and-Tracking/tree/master/OneStage/yolo/deep_sort_yolov3

* notes

to compile darknet with cuda and opencv, set GPU and OPENCV in the first few
lines of Makefile to 1

don't forget to ~ln -s /usr/lib/whatever/opencv/opencv.pc /usr/lib/pkgconfig/opencv.pc~

also apply that's guy's update patch:
(honestly, probably need the whole pr at
[https://github.com/pjreddie/darknet/pull/1348/commits]), but at least just
[https://github.com/pjreddie/darknet/pull/1348/commits/24cff08086b573c3341e91d072430c9f624a2208]
is good enough, might need to tweak a bit though

and force opencv4, otherwise it won't find opencv2/opencv.hpp
- my version of the aforementioned commit

and for ric, make sure to set env var:
~PKG_CONFIG_PATH=/usr/local/contrib/lib64/pkgconfig~
for opencv4. tbh the lib (non-64) version should be added as well, but with
what i set up on ric, opencv4 is the only pkgconfig in lib64, and all the
pkgconfigs in lib are for libav stuff.

and make sure to pick up the shared objects:
~LD_LIBRARY_PATH=/usr/local/contrib/lib64:$LD_LIBRARY_PATH~

also point to nvcc, either in the makefile with NVCC, or by adding to path
- ~/usr/local/cuda/bin~
- or ~/opt/cuda-10.1/bin~ on ric

also if you want to use opencv2 with python3 on ric:
~PYTHONPATH=/usr/local/contrib/lib/python3.6/site-packages:$PYTHONPATH~

to use the ffmpeg codecs on gstreamer:
~GST_PLUGIN_PATH=/usr/local/contrib/lib/gstreamer-1.0:$GST_PLUGIN_PATH~

hm, tf2 doesn't workg with the above pythonpath...? but installed --user
works?


when you run yolov3-tf2 make sure to remove the /opt cuda path from
LD_LIBRARY_PATH

and for darknet_video.py make sure to add . to LD_LIBRARY_PATH - oh wait you
only need to do that if you want to run yolo_console_dll (uselib), otherwise
for darknet_video.py you don't need anything special

also if you get that annoying qtwidget thread thing, just try completely
logging out and logging in again (ie. reset the entire ssh connection)

** some measurements (just comparing fps for now)

fps comparison for yolov3 implementations

all these tests were run on MOT17-02-DPM.mp4

- old darknet is with my wrapper
- yolov3-tf: [[https://github.com/zzh8829/yolov3-tf2]]
- tf2-ex: [[https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3]]

|        |new darknet|old darknet|yolov3-tf |tf2-ex|
|        | (fps)     |(fps)      |(fps)     |(fps) |
| min    |      0.00 |       0.39|      0.20|  0.50|
| 1st q  |      6.30 |       3.73|      2.76|  4.89|
| median |     16.90 |       7.04|      4.09|  4.96|
| 3rd q  |     26.70 |      11.93|      8.21|  5.00|
| max    |     46.00 |      13.04|     12.65|  5.25|
| mean   |     17.78 |       7.41|      5.86|  4.85|
| stddev |     12.05 |       3.52|      3.66|  0.48|

histogram of fps of my application (C) using old darknet for yolov3:

[[./img/yolov3-dn-fps.png]]

histogram of fps of python implementation of yolov3 with tf2-ex:

[[./img/yolov3-tf-fps.png]]

histogram of fps of new darknet for detection:

[[./img/darknet-new-fps-detect.png]]

histogram of fps of yolov3-tf:

[[./img/yolov3-tf2-fps-detect.png]]

* baseline

** First try

base darknet run
~./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg~

live detector
~./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights videofile~

on neptunite:
data/dog.jpg: Predicted in 12.952805 seconds.
dog: 100%
truck: 92%
bicycle: 99%

on peridot:
data/dog.jpg: Predicted in 79.676022 seconds.
dog: 100%
truck: 92%
bicycle: 99%

of course cpu takes longer on peridot :)


hm, regular run with real-time webcam crashes
137 = sigkill, probably oom?
let's try the tiny weights

it runs on tiny? but freezes? maybe network bw issue? let's try on hdmi
hm yeah looks like it crashed

hm looks like not enough power coz it sometimes crashes with just qv4l2 or
just regular image detection (with tiny weights)
imma get the 5V/4A power adapter
i only have 5V/2A right now :/

power adapter arrived! yolo tiny runs! but it can only recognize people...
and misclassified my watch as a cellphone once lol
i wonder if it can work with the regular yolo... nope, it still dies at step
17, probably oom
yeah it got killed by the oom killer - ah, we only have 4GB of ram
- swap? looks like it comes with 2GB of swap

great, undocumented parameters to detector demo
-w for width, -h for height, -fps for fps
and i think these extra params go after the cfgs and the weights and stuff
coz those use positional args
also after weights you can specify input file name

i got 10 fps with 480p! and 240p. and 160p.
8 fps with 720p
5 fps with 1080p

hm, 9 fps with motchallenge 17 @360p

** Getting the video codecs, on ric

hm darknet with an input video doesn't work for some reason :/
on ric at least; it works on neptunite

#+BEGIN_SRC log
./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights ../../one_evening_in_campo_santa_maria_nova_venice_1080p.mp4
...
video file: ../../one_evening_in_campo_santa_maria_nova_venice_1080p.mp4
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (1743) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (1743) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (1759) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module uridecodebin0 reported: Your GStreamer installation is missing a plug-in.
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (888) open OpenCV | GStreamer warning: unable to start pipeline
[ WARN:0] global /usr/local/contrib/opencv/src/modules/videoio/src/cap_gstreamer.cpp (480) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created
Couldn't connect to webcam.
: Success
darknet: ./src/utils.c:256: error: Assertion `0' failed.
zsh: abort (core dumped)  ./darknet detector demo cfg/coco.data
cfg/yolov3.cfg yolov3.weights 
#+END_SRC

hm list gstreamer plugins...
ah, ric is missing h264 decoder lol. and a bunch of other codecs actually
alright, i'll convert the video to... wait ffmpeg comes with libavcodec... is
that sufficient?

okay yeah i had to install ffmpeg (4.2.2) and then gst-libav (1.10.4, to
match the gstreamer version on ric). oh also needed meson to build gst-libav.
also set the environment variable: see above

okay so now the darknet demo detector works! on the "one evening in campo sant
maria nova venice" 1080p. i get 12~17 fps, and it segfaults :)

oops i guess i was running the wrong version of the video. this time i tried
MOT17-02-DPM. got 3~18 fps, and it still segfaults. it does get through most
(or all) of the video, though (but also it's only 40 seconds, and the last
one was a lot more).

** Fixing the segfault

okay here's the segfault:
#+BEGIN_SRC log
==51380== Process terminating with default action of signal 11 (SIGSEGV)
==51380==  Access not within mapped region at address 0x51F02D770
==51380==    at 0x9B30960: icv_l9_owniSwapChannels_8u_C3R (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_imgproc.so.4.2.0)
==51380==    by 0x9B2FDE6: icv_l9_ippiSwapChannels_8u_C3R (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_imgproc.so.4.2.0)
==51380==    by 0x96AF774: cv::CvtColorIPPLoop_Invoker<cv::IPPReorderFunctor>::operator()(cv::Range const&) const (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_imgproc.so.4.2.0)
==51380==    by 0xB0B963D: (anonymous namespace)::ParallelLoopBodyWrapper::operator()(cv::Range const&) const (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0xB0B9FDA: cv::ParallelJob::execute(bool) [clone .constprop.44] (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0xB0BAC9C: cv::WorkerThread::thread_body() (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0xB0BAE52: cv::WorkerThread::thread_loop_wrapper(void*) (in /afs/cs.pitt.edu/system/amd64_cen7/usr/local/contrib/lib64/libopencv_core.so.4.2.0)
==51380==    by 0x166B6DD4: start_thread (in /usr/lib64/libpthread-2.17.so)
==51380==    by 0x169C8EAC: clone (in /usr/lib64/libc-2.17.so)
==51380==  If you believe this happened as a result of a stack
==51380==  overflow in your program's main thread (unlikely but
==51380==  possible), you can try to increase the size of the
==51380==  main thread stack using the --main-stacksize= flag.
==51380==  The main thread stack size used in this run was 8388608.
==51380== 
==51380== HEAP SUMMARY:
==51380==     in use at exit: 7,464,752,931 bytes in 220,573 blocks
==51380==   total heap usage: 513,540 allocs, 292,967 frees, 8,719,829,795 bytes allocated
==51380== 
==51380== LEAK SUMMARY:
==51380==    definitely lost: 16,549 bytes in 2 blocks
==51380==    indirectly lost: 0 bytes in 0 blocks
==51380==      possibly lost: 4,179,136 bytes in 8,483 blocks
==51380==    still reachable: 7,460,360,630 bytes in 211,014 blocks
==51380==                       of which reachable via heuristic:
==51380==                         stdstring          : 11,695 bytes in 213 blocks
==51380==                         length64           : 11,680 bytes in 253 blocks
==51380==                         newarray           : 2,112 bytes in 52 blocks
==51380==         suppressed: 0 bytes in 0 blocks
==51380== Rerun with --leak-check=full to see details of leaked memory
==51380== 
==51380== For counts of detected and suppressed errors, rerun with: -v
==51380== Use --track-origins=yes to see where uninitialised values come from
==51380== ERROR SUMMARY: 10000000 errors from 5 contexts (suppressed: 0 from 0)
zsh: segmentation fault (core dumped)  valgrind ./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights 
#+END_SRC

ah, this is the right segfault (i think):

#+BEGIN_SRC log
==61104== 
==61104== Process terminating with default action of signal 8 (SIGFPE)
==61104==  Integer divide by zero at address 0x1012255804
==61104==    at 0x490B78: correct_yolo_boxes (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x491263: get_yolo_detections (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x4627C7: fill_network_boxes (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x46297E: get_network_boxes (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x480477: detect_in_thread (in /afs/cs.pitt.edu/usr0/pye1/cs-2910-gh/darknet/darknet)
==61104==    by 0x166B6DD4: start_thread (in /usr/lib64/libpthread-2.17.so)
==61104==    by 0x169C8EAC: clone (in /usr/lib64/libc-2.17.so)
==61104== 
==61104== HEAP SUMMARY:
==61104==     in use at exit: 7,378,105,383 bytes in 217,404 blocks
==61104==   total heap usage: 717,776 allocs, 500,372 frees, 22,314,494,019 bytes allocated
==61104== 
==61104== LEAK SUMMARY:
==61104==    definitely lost: 16,549 bytes in 2 blocks
==61104==    indirectly lost: 0 bytes in 0 blocks
==61104==      possibly lost: 3,315,272 bytes in 8,484 blocks
==61104==    still reachable: 7,374,577,706 bytes in 207,847 blocks
==61104==                       of which reachable via heuristic:
==61104==                         stdstring          : 11,695 bytes in 213 blocks
==61104==                         length64           : 11,680 bytes in 253 blocks
==61104==                         newarray           : 2,112 bytes in 52 blocks
==61104==         suppressed: 0 bytes in 0 blocks
==61104== Rerun with --leak-check=full to see details of leaked memory
==61104== 
==61104== For counts of detected and suppressed errors, rerun with: -v
==61104== Use --track-origins=yes to see where uninitialised values come from
==61104== ERROR SUMMARY: 10000000 errors from 5 contexts (suppressed: 0 from 0)
zsh: floating point exception (core dumped)  valgrind ./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights 
#+END_SRC

okay let's start the debugging
- oh wait valgrind already gave us the callstack lol

#+BEGIN_SRC call stack
start_thread
> detect_in_thread
  > get_network_boxes
    > fill_network_boxes
      > get_yolo_detection
        > correct_yolo_boxes
#+END_SRC

hm okay so i actually checked all my debug prints, and they all have 960x540,
which is the resolution of the video. when the program crashes with the
divide-by-zero, those are zero
- soooo maybe it's the last frame that's killing it?

i think it's not stopping at all actually

so ~get_network_boxes~ (from ~avg_preditions~ in ~detect_in_thread~) gets the
buffer height and width from the global video buffer ring buffer, which has
zeroes, and causes ~correct_yolo_boxes~ down the call stack to divide-by-zero

- ~get_image_from_stream()~ returns an empty 0x0 frame when no frame is
  available
- global video buffer rig buffer ~buff~
- set ~demo_done~ to true when done

ah, okay ~fetch_in_thread()~ does actually set ~demo_done~ to true when
~get_image_from_stream()~ returns an empty frame
- the problem is that ~fetch_in_thread()~ and ~detect_in_thread()~ are both
  in separate threads, racing :)
  - i think the solution is to just put an extra layer of protection in
    ~detect_in_thread()~, such that if the height and width are zero, then
    don't do anything (coz ~fetch_in_thread()~ is alraedy going to end the
    demo loop, so we just have to avoid the crash)

oh also it looks like ~avg_predictions~ was using buff index 0 all the time
so i fixed that to buff_index (log2)

and yeah i added extra protection in ~detect_in_thread()~ to exit if the
frame size is zero. it worked! (log3)

so now time to actually put stuff together

** Putting stuff together

idk if this helps? anyway saving the link just in case
[[https://github.com/entrehuihui/darknet-golang/]]

~parse_network_cfg~

oh yeah forgot to note down that the entry point is in ~examples/darknet~

there's ~run_detector()~ and ~test_detector()~... i wonder how different they
are
- this might be the key to making a simple enough pipeline :)
- then just need to hook it up with the C++ deep sort implementation...

okay so im comparing from ~test_detector()~ to ~run_detector()~:

#+BEGIN_SRC C
read_data_cfg()
option_find_str(..., "data/names.list")
get_labels()
// then ~run_detector()~ calls ~demo()~
load_alphabet()
load_network()
set_batch_network()
#+END_SRC

okay im pretty sure that's the initialization... let's go ahead and burn that
to a file

function prototype for our ~test_detector()~, with default values:
#+BEGIN_SRC C
void test_detector(char *datacfg : "cfg/coco.data",
                   char *cfgfile : "cfg/yolov3.cfg",
                   char *weightfile : "yolov3.weights",
                   char *filename : data/dog.jpg,
                   float thresh : 0.5,
                   float hier_thresh : 0.5,
                   char *outfile : outfile,
                   int fullscreen : fullscreen);
#+END_SRC

after that... (for single image)
#+BEGIN_SRC C
float *X = sized.data;
time = what_time_is_it_now();
network_predict(net, X);
printf("%s: Predicted in %f seconds.\n", input, what_time_is_it_now()-time);

int nboxes = 0;
detection *dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, 0, 1, &nboxes);
if (nms)
      do_nms_sort(dets, nboxes, l.classes, nms);

draw_detections(im, dets, nboxes, thresh, names, alphabet, l.classes);
free_detections(dets, nboxes);
#+END_SRC

okay i think i got a minimal darknet application

** Misc stuff from putting stuff together

after ~network_predict(net, X);~:
#+BEGIN_SRC C
// not sure what this does; anyway it comes from demo
// copy if you need it, but let's try without for now
// remember_network(net);
#+END_SRC

pretty sure we can ignore the ret val of this, coz i think it's just a keycode?

Not necessary to make a window, coz we'll draw the frames later

Not sure what ~set_batch_network()~ does

** Connecting the detector

hm so the original implementation is in python:
[[https://github.com/nwojke/deep_sort]]

and there are some c++ implementations...
- [[https://github.com/oylz/DS]] - old, can't get it to compile
- [[https://github.com/apennisi/deep_sort]] - looks promising
- [[https://github.com/shaoshengsong/DeepSORT]] - not sure, but another one
  in case the previous one fails

in the worst case maybe i'll call into python or something... or implement my
own :/

** Converting to tensorflor

Mosse and Ridrigo recommend that i switch to tf... that might be better
actually :/

DS doesn't want to play nice with boost...

tf is having a hard time compiling... i hope it works

pip worked for some reason

also deep_sort (C++) didn't work coz boost version mismatch? missing header

and DeepSort (also C++) has no build so um yeah :/

we're going to have to go with the tf implementations...

hm... i have a guess deep_sort from deep_sort_yolov3 doesn't depend on tf at
all (the yolov3 portion depends on tf1), so we might actually be able to use
that in python darknet... let's see :)
- from here [[https://github.com/Qidian213/deep_sort_yolov3/]]

*** new darknet python detections format

[bytestring of label, confidence, bounding box]

[(b'person', 0.9992530941963196, (308.0138244628906, 232.64064025878906,
38.53749084472656, 138.75567626953125)), (b'person', 0.9866634607315063,
(137.091064453125, 220.35328674316406, 25.921817779541016, 97.487060546875)),
(b'person', 0.9322742819786072, (162.37936401367188, 198.82156372070312,
9.020377159118652, 42.37779235839844)), (b'person', 0.837138831615448,
(375.0699462890625, 200.4085235595703, 22.553640365600586,
59.19319534301758)), (b'person', 0.8317587971687317, (330.0757751464844,
229.74639892578125, 26.68379020690918, 108.94158935546875)), (b'person',
0.7632826566696167, (106.59329223632812, 226.11199951171875,
26.079158782958984, 100.47222137451172)), (b'person', 0.7058770060539246,
(276.49200439453125, 189.14573669433594, 8.444928169250488,
41.20795440673828)), (b'handbag', 0.5843681693077087, (97.74515533447266,
226.93496704101562, 18.03496551513672, 24.689504623413086)), (b'umbrella',
0.5733580589294434, (374.95709228515625, 163.89324951171875,
25.796112060546875, 9.90929126739502)), (b'person', 0.5225788354873657,
(153.6721954345703, 204.23947143554688, 8.81717300415039,
52.854156494140625)), (b'person', 0.43799227476119995, (406.5743713378906,
215.89390563964844, 15.703649520874023, 74.89576721191406)), (b'person',
0.41168326139450073, (241.92977905273438, 194.4013671875, 10.230013847351074,
47.96332550048828)), (b'person', 0.3753121793270111, (206.500732421875,
182.40682983398438, 7.391855716705322, 32.68758010864258)), (b'person',
0.32717615365982056, (122.51595306396484, 195.37823486328125,
9.457942008972168, 36.52040481567383)), (b'person', 0.27769872546195984,
(226.16036987304688, 187.29954528808594, 8.413454055786133,
36.14714431762695)), (b'person', 0.27708911895751953, (286.1336669921875,
187.1359100341797, 9.223457336425781, 45.986568450927734))]

yep, here's the code:

~res.append((nameTag, dets[j].prob[i], (b.x, b.y, b.w, b.h)))~

and deep sort expects detections like:

~def __init__(self, tlwh, confidence, feature):~

where tlwh is bbox (x, y, w, h), confidence is confidence, and feature is
array_like: "a feature vector that describes the object contained in this
image"
- darn how can i get that from darknet...

** back to new darknet

okay looks like we only have opencv; no zed and stuff

okay so the original yolo_console_dll had a single buffer between the stages
- i chagned the queue and now we're monitoring it every 10ms, but only one
  buffer is being used...
- except for when we turn on image display, then that buffer is the bottlneck
- when we turn off display we have a flat 15 fps
  - the original video is 25 fps

** Documentation for our version

gpu is required

optional ~-i N~ - N to set the gpu index (default 0)

* code stuff

okay while waiting for the adapter, let's check the code
entry point is ~examples/detector.c:run_detector()~
that calls into ~src/demo.c:demo()~, which is the main run loop for the thing
and then ~fetch_in_thread()~ and ~detect_in_thread()~ is the main contents of the
loop
looks like all symbols are exported by libdarknet so it shouldn't be that
hard to stitch together? anyway im not done reading fetch and detect yet

~fetch_in_thread()~:
- free buffer
- get buffer from stream: ~src/image_opencv.cpp:get_image_from_stream()~
- put the boxed image into the main image buffer: ~src/image.c:letterbox_image_into()~

where does buff_letter come from? it is predicted from the last frame in
~detect_in_thread()~?

~letterbox_image_into()~:
- ~resize_image()~ (i think it's resizing to the size of the bounding box?)
- ~embed_image()~ - puts an image into an image... here it's putting the boxed
  image into the main image it looks like
- ~free_image()~ - free the temporarily allocated ~image from resize_image()~

~detect_in_thread()~:
- i think applying the network: ~src/network.c:network_predict()~
- im guessing caching the network/application: ~src/demo.c:remember_network()~
- not sure: ~src/demo.c:avg_predictions()~
  - goes into ~src/box.c:do_nms_obj()~
    - i have no idea what this does - thanks for the commit message: "MERRY
      CHRISTMAS I BROKE ALL YOUR DETECTION THINGS"
- ~draw_detections()~
- ~free_detections()~, and update the (global) buffer index

~src/network.c:network_predict()~:
- ~forward_network()~ -> ~forward_network_gpu()~
  - cuda stuff
